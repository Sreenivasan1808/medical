{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3356e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f64a346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               1152      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 64)                256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16)                64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8)                 32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17569 (68.63 KB)\n",
      "Trainable params: 16945 (66.19 KB)\n",
      "Non-trainable params: 624 (2.44 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 5s 40ms/step - loss: 0.8652 - accuracy: 0.4969 - auc: 0.4564 - val_loss: 0.6768 - val_accuracy: 0.6423 - val_auc: 0.5565\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7522 - accuracy: 0.5458 - auc: 0.5501 - val_loss: 0.6591 - val_accuracy: 0.6423 - val_auc: 0.7244\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7290 - accuracy: 0.5845 - auc: 0.5953 - val_loss: 0.6398 - val_accuracy: 0.6585 - val_auc: 0.7839\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7220 - accuracy: 0.6029 - auc: 0.6016 - val_loss: 0.6231 - val_accuracy: 0.6992 - val_auc: 0.7999\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.7039 - accuracy: 0.6293 - auc: 0.6060 - val_loss: 0.6084 - val_accuracy: 0.7480 - val_auc: 0.8085\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6698 - accuracy: 0.6090 - auc: 0.6258 - val_loss: 0.5985 - val_accuracy: 0.7398 - val_auc: 0.8098\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6617 - accuracy: 0.6456 - auc: 0.6362 - val_loss: 0.5864 - val_accuracy: 0.7398 - val_auc: 0.8277\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6267 - accuracy: 0.6415 - auc: 0.6690 - val_loss: 0.5780 - val_accuracy: 0.7561 - val_auc: 0.8344\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6928 - accuracy: 0.6517 - auc: 0.6243 - val_loss: 0.5669 - val_accuracy: 0.7642 - val_auc: 0.8470\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5947 - accuracy: 0.6965 - auc: 0.7097 - val_loss: 0.5564 - val_accuracy: 0.7561 - val_auc: 0.8501\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.6386 - accuracy: 0.6782 - auc: 0.6586 - val_loss: 0.5461 - val_accuracy: 0.7561 - val_auc: 0.8413\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.6538 - auc: 0.6583 - val_loss: 0.5418 - val_accuracy: 0.7642 - val_auc: 0.8336\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.6823 - auc: 0.6971 - val_loss: 0.5379 - val_accuracy: 0.7642 - val_auc: 0.8298\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5806 - accuracy: 0.6986 - auc: 0.7286 - val_loss: 0.5333 - val_accuracy: 0.7561 - val_auc: 0.8248\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5797 - accuracy: 0.7006 - auc: 0.7149 - val_loss: 0.5225 - val_accuracy: 0.7642 - val_auc: 0.8409\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.6084 - accuracy: 0.6782 - auc: 0.6766 - val_loss: 0.5130 - val_accuracy: 0.7886 - val_auc: 0.8412\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5709 - accuracy: 0.7047 - auc: 0.7278 - val_loss: 0.5065 - val_accuracy: 0.7967 - val_auc: 0.8396\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.7169 - auc: 0.7385 - val_loss: 0.5012 - val_accuracy: 0.7886 - val_auc: 0.8393\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5680 - accuracy: 0.7149 - auc: 0.7370 - val_loss: 0.4965 - val_accuracy: 0.7967 - val_auc: 0.8388\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5758 - accuracy: 0.7128 - auc: 0.7209 - val_loss: 0.4906 - val_accuracy: 0.8130 - val_auc: 0.8425\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5808 - accuracy: 0.7291 - auc: 0.7211 - val_loss: 0.4843 - val_accuracy: 0.8130 - val_auc: 0.8461\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5544 - accuracy: 0.7312 - auc: 0.7668 - val_loss: 0.4808 - val_accuracy: 0.7886 - val_auc: 0.8494\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5496 - accuracy: 0.7413 - auc: 0.7544 - val_loss: 0.4775 - val_accuracy: 0.7886 - val_auc: 0.8543\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5406 - accuracy: 0.7637 - auc: 0.7697 - val_loss: 0.4748 - val_accuracy: 0.7805 - val_auc: 0.8557\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5696 - accuracy: 0.7312 - auc: 0.7428 - val_loss: 0.4735 - val_accuracy: 0.7805 - val_auc: 0.8533\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5478 - accuracy: 0.7271 - auc: 0.7496 - val_loss: 0.4719 - val_accuracy: 0.7805 - val_auc: 0.8569\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5550 - accuracy: 0.7291 - auc: 0.7562 - val_loss: 0.4669 - val_accuracy: 0.7724 - val_auc: 0.8623\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.5540 - accuracy: 0.7251 - auc: 0.7561 - val_loss: 0.4621 - val_accuracy: 0.7805 - val_auc: 0.8629\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.7352 - auc: 0.7348 - val_loss: 0.4562 - val_accuracy: 0.7805 - val_auc: 0.8605\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5527 - accuracy: 0.7108 - auc: 0.7430 - val_loss: 0.4518 - val_accuracy: 0.7886 - val_auc: 0.8636\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5413 - accuracy: 0.7434 - auc: 0.7766 - val_loss: 0.4481 - val_accuracy: 0.7886 - val_auc: 0.8661\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5356 - accuracy: 0.7475 - auc: 0.7621 - val_loss: 0.4443 - val_accuracy: 0.7805 - val_auc: 0.8664\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5516 - accuracy: 0.7189 - auc: 0.7657 - val_loss: 0.4437 - val_accuracy: 0.7967 - val_auc: 0.8659\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5466 - accuracy: 0.7169 - auc: 0.7652 - val_loss: 0.4434 - val_accuracy: 0.7886 - val_auc: 0.8661\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5342 - accuracy: 0.7210 - auc: 0.7672 - val_loss: 0.4420 - val_accuracy: 0.7886 - val_auc: 0.8659\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5234 - accuracy: 0.7373 - auc: 0.7916 - val_loss: 0.4391 - val_accuracy: 0.8049 - val_auc: 0.8667\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.7536 - auc: 0.8033 - val_loss: 0.4387 - val_accuracy: 0.8049 - val_auc: 0.8682\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5336 - accuracy: 0.7149 - auc: 0.7820 - val_loss: 0.4382 - val_accuracy: 0.8049 - val_auc: 0.8669\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5550 - accuracy: 0.7291 - auc: 0.7687 - val_loss: 0.4359 - val_accuracy: 0.8049 - val_auc: 0.8662\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5091 - accuracy: 0.7515 - auc: 0.8074 - val_loss: 0.4363 - val_accuracy: 0.8130 - val_auc: 0.8690\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5513 - accuracy: 0.7434 - auc: 0.7665 - val_loss: 0.4380 - val_accuracy: 0.8049 - val_auc: 0.8682\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.7536 - auc: 0.8045 - val_loss: 0.4367 - val_accuracy: 0.8130 - val_auc: 0.8688\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.4899 - accuracy: 0.7536 - auc: 0.8147 - val_loss: 0.4376 - val_accuracy: 0.8049 - val_auc: 0.8657\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.7699 - auc: 0.8237 - val_loss: 0.4383 - val_accuracy: 0.8049 - val_auc: 0.8618\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7454 - auc: 0.7980 - val_loss: 0.4381 - val_accuracy: 0.7967 - val_auc: 0.8641\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5122 - accuracy: 0.7576 - auc: 0.8043 - val_loss: 0.4371 - val_accuracy: 0.7967 - val_auc: 0.8668\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5071 - accuracy: 0.7719 - auc: 0.8024 - val_loss: 0.4306 - val_accuracy: 0.8049 - val_auc: 0.8695\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4919 - accuracy: 0.7780 - auc: 0.8104 - val_loss: 0.4321 - val_accuracy: 0.8049 - val_auc: 0.8701\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4887 - accuracy: 0.7841 - auc: 0.8208 - val_loss: 0.4301 - val_accuracy: 0.8049 - val_auc: 0.8717\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.7454 - auc: 0.7854 - val_loss: 0.4252 - val_accuracy: 0.8049 - val_auc: 0.8757\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 9ms/step - loss: 0.5171 - accuracy: 0.7352 - auc: 0.7881 - val_loss: 0.4203 - val_accuracy: 0.8049 - val_auc: 0.8780\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5249 - accuracy: 0.7515 - auc: 0.7811 - val_loss: 0.4225 - val_accuracy: 0.7967 - val_auc: 0.8777\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.5003 - accuracy: 0.7597 - auc: 0.8163 - val_loss: 0.4231 - val_accuracy: 0.8130 - val_auc: 0.8759\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.7556 - auc: 0.8207 - val_loss: 0.4222 - val_accuracy: 0.8130 - val_auc: 0.8754\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4898 - accuracy: 0.7862 - auc: 0.8209 - val_loss: 0.4236 - val_accuracy: 0.8049 - val_auc: 0.8749\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4931 - accuracy: 0.7821 - auc: 0.8181 - val_loss: 0.4275 - val_accuracy: 0.8049 - val_auc: 0.8731\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4823 - accuracy: 0.7821 - auc: 0.8255 - val_loss: 0.4264 - val_accuracy: 0.8049 - val_auc: 0.8750\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4691 - accuracy: 0.7556 - auc: 0.8380 - val_loss: 0.4224 - val_accuracy: 0.8130 - val_auc: 0.8786\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4834 - accuracy: 0.7760 - auc: 0.8256 - val_loss: 0.4213 - val_accuracy: 0.8130 - val_auc: 0.8779\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4953 - accuracy: 0.7821 - auc: 0.8189 - val_loss: 0.4222 - val_accuracy: 0.8130 - val_auc: 0.8769\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 10ms/step - loss: 0.4690 - accuracy: 0.7637 - auc: 0.8449 - val_loss: 0.4235 - val_accuracy: 0.8130 - val_auc: 0.8753\n",
      "Test Accuracy: 0.7532, Test AUC: 0.8043\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load your data\n",
    "# Replace 'your_data.csv' with the path to your dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# 2. Split into features and target\n",
    "X = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
    "        'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']].values\n",
    "y = df['Outcome'].values\n",
    "\n",
    "# 3. Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 5. Build a deeper model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')  # output layer\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 6. Train with early stopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 7. Evaluate on the test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test AUC: {test_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
